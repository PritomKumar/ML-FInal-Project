{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bangla Handwritten letter version 64.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6aAerR1srFR",
        "outputId": "8e5c0f1b-ac08-4e3f-ba26-660c0e79291b"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (54.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.28.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtBJmwAN3jp2",
        "outputId": "751213bf-d83c-4ac9-b10c-c88ae5d949c1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 11 09:45:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVxseEjw4eLi"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdvbGAx49LSD"
      },
      "source": [
        "# **Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mAMR0nR9VR9"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBhKitnY9yXm"
      },
      "source": [
        "size = 100\n",
        "IMAGE_SIZE = [size,size ]\n",
        "path = '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/'\n",
        "\n",
        "train_path = path + 'Train'\n",
        "test_path = path + 'Test'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUdu2wl2-3Xk"
      },
      "source": [
        "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFZtta3z_EAN",
        "outputId": "917d7b24-7a36-42f1-a92d-a58a94b6c52f"
      },
      "source": [
        "# don't train existing weights\n",
        "# for layer in inception.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "folders = glob(train_path + '/*')\n",
        "\n",
        "folders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/181',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/178',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/172',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/177',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/179',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/174',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/180',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/176',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/173',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/175',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/182',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/187',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/189',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/190',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/188',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/191',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/183',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/186',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/185',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/184',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/201',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/199',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/200',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/195',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/192',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/196',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/194',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/197',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/198',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/193',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/206',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/207',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/204',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/205',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/203',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/208',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/202',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/210',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/211',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/209',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/212',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/213',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/218',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/215',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/216',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/220',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/219',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/214',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/221',\n",
              " '/content/drive/MyDrive/Datasets/BasicFinalDatabase100Basic/Train/217']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqug96RB_wwg",
        "outputId": "2e575e29-4e2e-43c8-a027-d14d778384e4"
      },
      "source": [
        "x = Flatten()(inception.output)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=inception.input, outputs=prediction)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 49, 49, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 49, 49, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 49, 49, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 47, 47, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 47, 47, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 47, 47, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 47, 47, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 47, 47, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 47, 47, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 23, 23, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 23, 23, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 23, 23, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 23, 23, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 21, 21, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 21, 21, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 21, 21, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 10, 10, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 10, 10, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 10, 10, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 10, 10, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 10, 10, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 10, 10, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 10, 10, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 10, 10, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 10, 10, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 10, 10, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 10, 10, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 10, 10, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 10, 10, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 10, 10, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 10, 10, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 10, 10, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 10, 10, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 10, 10, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 10, 10, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 10, 10, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 10, 10, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 10, 10, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 10, 10, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 10, 10, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 10, 10, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 10, 10, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 10, 10, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 10, 10, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 10, 10, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 10, 10, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 10, 10, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 10, 10, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 10, 10, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 10, 10, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 10, 10, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 10, 10, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 10, 10, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 10, 10, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 10, 10, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 10, 10, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 10, 10, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 10, 10, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 10, 10, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 10, 10, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 10, 10, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 10, 10, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 10, 10, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 10, 10, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 10, 10, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 10, 10, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 10, 10, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 10, 10, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 10, 10, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 10, 10, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 10, 10, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 10, 10, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 10, 10, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 10, 10, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 10, 10, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 10, 10, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 10, 10, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 10, 10, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 4, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 4, 4, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 4, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 4, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 4, 4, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 4, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 4, 4, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 4, 4, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 4, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 4, 4, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 4, 4, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 4, 4, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 4, 4, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 4, 4, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 4, 4, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 4, 4, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 4, 4, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 4, 4, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 4, 4, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 4, 4, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 4, 4, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 4, 4, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 4, 4, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 4, 4, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 4, 4, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 4, 4, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 4, 4, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 4, 4, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 4, 4, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 4, 4, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 4, 4, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 4, 4, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 4, 4, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 4, 4, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 4, 4, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 4, 4, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 4, 4, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 4, 4, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 4, 4, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 4, 4, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 4, 4, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 4, 4, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 4, 4, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 4, 4, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 4, 4, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 4, 4, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 4, 4, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 4, 4, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 4, 4, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 4, 4, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 4, 4, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 4, 4, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 4, 4, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 4, 4, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 4, 4, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 4, 4, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 4, 4, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 4, 4, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 4, 4, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 4, 4, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 4, 4, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 4, 4, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 1, 1, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 1, 1, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1, 1, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 1, 1, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 1, 1, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 1, 1, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 1, 1, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 1, 1, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 1, 1, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 1, 1, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 1, 1, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 1, 1, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 1, 1, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 1, 1, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 1, 1, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 1, 1, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 1, 1, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 1, 1, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 1, 1, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 1, 1, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 1, 1, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 1, 1, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 1, 1, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 1, 1, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 1, 1, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 1, 1, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           102450      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,905,234\n",
            "Trainable params: 21,870,802\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt-SVf2uAFWO"
      },
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OChnXboWAfy8"
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
        "checkpoint = ModelCheckpoint('handwrittern bangla letter100v2.h5', verbose=1, save_best_only=True)\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LmNI1eHAvgG",
        "outputId": "1fff8ef9-0a13-43e9-b64c-a38ab079427f"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (size, size),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12036 images belonging to 50 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pmTTg2qBE-n",
        "outputId": "52aa2be4-98ba-4690-ca71-a14eb4afd319"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (size, size),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3000 images belonging to 50 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVBxj-MZEWFD",
        "outputId": "fe357ef4-e6f9-41fd-fbae-21a1320519e5"
      },
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=100,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  callbacks=[anne, checkpoint],\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "377/377 [==============================] - 77s 180ms/step - loss: 3.4648 - accuracy: 0.1528 - val_loss: 4.1674 - val_accuracy: 0.4707\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.16744, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 1.4274 - accuracy: 0.6227 - val_loss: 2.0635 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.16744 to 2.06352, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.9531 - accuracy: 0.7425 - val_loss: 11.5697 - val_accuracy: 0.5113\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2.06352\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.9297 - accuracy: 0.7439 - val_loss: 0.9765 - val_accuracy: 0.8197\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.06352 to 0.97654, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.5986 - accuracy: 0.8296 - val_loss: 1.2658 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.97654\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.4868 - accuracy: 0.8729 - val_loss: 0.2987 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.97654 to 0.29865, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.4981 - accuracy: 0.8676 - val_loss: 2.8076 - val_accuracy: 0.7270\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.29865\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.4007 - accuracy: 0.8903 - val_loss: 0.2636 - val_accuracy: 0.9183\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.29865 to 0.26363, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.2967 - accuracy: 0.9132 - val_loss: 0.2650 - val_accuracy: 0.9290\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.26363\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 64s 171ms/step - loss: 0.2305 - accuracy: 0.9313 - val_loss: 0.2387 - val_accuracy: 0.9297\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.26363 to 0.23869, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.4116 - accuracy: 0.8951 - val_loss: 0.2496 - val_accuracy: 0.9233\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.23869\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.2652 - accuracy: 0.9226 - val_loss: 0.2404 - val_accuracy: 0.9277\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.23869\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.3073 - accuracy: 0.9165 - val_loss: 0.3210 - val_accuracy: 0.9120\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.23869\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.2783 - accuracy: 0.9215 - val_loss: 0.1641 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.23869 to 0.16415, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.7973 - accuracy: 0.8304 - val_loss: 0.2838 - val_accuracy: 0.9110\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.16415\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.2451 - accuracy: 0.9307 - val_loss: 0.3179 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.16415\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.2397 - accuracy: 0.9312 - val_loss: 0.1951 - val_accuracy: 0.9383\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.16415\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.1924 - accuracy: 0.9455 - val_loss: 0.2218 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.16415\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 64s 171ms/step - loss: 0.1797 - accuracy: 0.9481 - val_loss: 0.2050 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.16415\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1705 - accuracy: 0.9466 - val_loss: 0.1707 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.16415\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.1729 - accuracy: 0.9484 - val_loss: 1.2777 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.16415\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.1732 - accuracy: 0.9535 - val_loss: 0.2714 - val_accuracy: 0.9430\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.16415\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.2194 - accuracy: 0.9344 - val_loss: 0.1911 - val_accuracy: 0.9417\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.16415\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.2019 - accuracy: 0.9409 - val_loss: 0.1685 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.16415\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1292 - accuracy: 0.9595 - val_loss: 0.2413 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.16415\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1192 - accuracy: 0.9624 - val_loss: 0.1487 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.16415 to 0.14870, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.1393 - accuracy: 0.9563 - val_loss: 0.6150 - val_accuracy: 0.8460\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.14870\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 66s 175ms/step - loss: 0.1982 - accuracy: 0.9410 - val_loss: 0.1279 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.14870 to 0.12786, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1106 - accuracy: 0.9662 - val_loss: 0.3474 - val_accuracy: 0.9040\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.12786\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1202 - accuracy: 0.9657 - val_loss: 0.3225 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.12786\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1195 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.12786 to 0.11954, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0919 - accuracy: 0.9701 - val_loss: 0.1295 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.11954\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.1899 - accuracy: 0.9521 - val_loss: 0.2800 - val_accuracy: 0.9213\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.11954\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.1545 - accuracy: 0.9549 - val_loss: 0.7115 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.11954\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1499 - accuracy: 0.9595 - val_loss: 0.1270 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.11954\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0900 - accuracy: 0.9732 - val_loss: 0.1060 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.11954 to 0.10596, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1093 - accuracy: 0.9681 - val_loss: 0.2078 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.10596\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0724 - accuracy: 0.9773 - val_loss: 0.1163 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.10596\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.1156 - accuracy: 0.9668 - val_loss: 0.1626 - val_accuracy: 0.9510\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.10596\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.1075 - accuracy: 0.9681 - val_loss: 0.1174 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.10596\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.1663 - accuracy: 0.9564 - val_loss: 0.1989 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.10596\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.1114 - accuracy: 0.9649 - val_loss: 0.5094 - val_accuracy: 0.8683\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.10596\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.1695 - accuracy: 0.9493 - val_loss: 0.1348 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.10596\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0889 - accuracy: 0.9716 - val_loss: 0.1123 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.10596\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.6532 - val_accuracy: 0.8367\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.10596\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.0926 - accuracy: 0.9698 - val_loss: 0.1040 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.10596 to 0.10401, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.1246 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.10401\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.1430 - accuracy: 0.9620 - val_loss: 0.1269 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.10401\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.2264 - accuracy: 0.9392 - val_loss: 0.1032 - val_accuracy: 0.9713\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.10401 to 0.10320, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.0892 - accuracy: 0.9729 - val_loss: 0.2460 - val_accuracy: 0.9380\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.10320\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.1051 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.10320\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 62s 165ms/step - loss: 0.0653 - accuracy: 0.9814 - val_loss: 0.1252 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.10320\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 62s 164ms/step - loss: 0.0736 - accuracy: 0.9763 - val_loss: 0.1402 - val_accuracy: 0.9573\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.10320\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 61s 163ms/step - loss: 0.0834 - accuracy: 0.9765 - val_loss: 0.1149 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.10320\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 62s 164ms/step - loss: 0.0549 - accuracy: 0.9845 - val_loss: 0.1119 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.10320\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 62s 164ms/step - loss: 0.0762 - accuracy: 0.9764 - val_loss: 0.3205 - val_accuracy: 0.9243\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.10320\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 62s 165ms/step - loss: 0.1321 - accuracy: 0.9674 - val_loss: 0.1784 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.10320\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 62s 165ms/step - loss: 0.0478 - accuracy: 0.9837 - val_loss: 0.1083 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.10320\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 62s 164ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.0979 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.10320 to 0.09790, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.2326 - val_accuracy: 0.9493\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.09790\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0985 - accuracy: 0.9741 - val_loss: 0.1639 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.09790\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 65s 174ms/step - loss: 0.0836 - accuracy: 0.9755 - val_loss: 0.1338 - val_accuracy: 0.9687\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.09790\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.0718 - accuracy: 0.9789 - val_loss: 3.9157 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.09790\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.1203 - accuracy: 0.9694 - val_loss: 0.1298 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.09790\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 63s 166ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.1923 - val_accuracy: 0.9477\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.09790\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.1075 - val_accuracy: 0.9697\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.09790\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 63s 166ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.1190 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.09790\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.0973 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.09790 to 0.09728, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 62s 164ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.1445 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.09728\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 63s 166ms/step - loss: 0.0562 - accuracy: 0.9852 - val_loss: 0.1208 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.09728\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 62s 165ms/step - loss: 0.0762 - accuracy: 0.9807 - val_loss: 0.2907 - val_accuracy: 0.9407\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.09728\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 66s 175ms/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 0.1066 - val_accuracy: 0.9683\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.09728\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0656 - accuracy: 0.9814 - val_loss: 0.1448 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.09728\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.0763 - accuracy: 0.9808 - val_loss: 0.1072 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.09728\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 0.0986 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.09728\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.0813 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.09728 to 0.08127, saving model to handwrittern bangla letter100v2.h5\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0651 - accuracy: 0.9834 - val_loss: 0.1303 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.08127\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 0.1318 - val_accuracy: 0.9627\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.08127\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 64s 171ms/step - loss: 0.0659 - accuracy: 0.9812 - val_loss: 0.0961 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.08127\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0464 - accuracy: 0.9860 - val_loss: 0.1131 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.08127\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.1149 - accuracy: 0.9698 - val_loss: 0.0914 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.08127\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 66s 174ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.1733 - val_accuracy: 0.9560\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.08127\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.1332 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.08127\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 1.0441 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.08127\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.1123 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.08127\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0407 - accuracy: 0.9882 - val_loss: 0.2313 - val_accuracy: 0.9497\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.08127\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.08127\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 63s 166ms/step - loss: 0.0367 - accuracy: 0.9874 - val_loss: 0.2499 - val_accuracy: 0.9357\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.08127\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.0482 - accuracy: 0.9864 - val_loss: 0.1098 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.08127\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 65s 173ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.3058 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.08127\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 65s 172ms/step - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.1313 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.08127\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 64s 169ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.08127\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.0894 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.08127\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 63s 168ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0840 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.08127\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.1125 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.08127\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0722 - accuracy: 0.9836 - val_loss: 0.1366 - val_accuracy: 0.9677\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.08127\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 63s 167ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1070 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.08127\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.0898 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.08127\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 64s 170ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.1178 - val_accuracy: 0.9633\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.08127\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 65s 171ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.0822 - val_accuracy: 0.9770\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.08127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "qidsuQ3sVJHT",
        "outputId": "2cc47243-c59b-42eb-e5ec-8ef6072a652a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5FC_F4HVdzr"
      },
      "source": [
        "# save it as a h5 file\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('handwrittern bangla letter100v2.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLqEYXVdVjCJ",
        "outputId": "309c5e0e-adb7-4724-e50f-93a6d4b69963"
      },
      "source": [
        "y_pred = model.predict(test_set)\n",
        "y_pred"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5621161e-15, 2.0874741e-13, 7.2855799e-10, ..., 1.7272281e-11,\n",
              "        4.3154334e-11, 4.4185858e-16],\n",
              "       [1.9764874e-13, 1.2792529e-16, 6.4507294e-22, ..., 6.9302176e-13,\n",
              "        1.7402212e-15, 1.0000000e+00],\n",
              "       [1.8404590e-09, 3.5616052e-09, 1.4354303e-09, ..., 3.2948124e-06,\n",
              "        1.2699573e-11, 1.7354396e-04],\n",
              "       ...,\n",
              "       [1.3109119e-04, 5.2481875e-05, 6.8159585e-07, ..., 3.8712597e-06,\n",
              "        1.1340842e-06, 9.0610399e-04],\n",
              "       [4.7276972e-04, 1.0211412e-05, 2.6031582e-10, ..., 2.6169137e-06,\n",
              "        5.2058748e-09, 9.9937147e-01],\n",
              "       [2.0025668e-18, 1.7001983e-18, 2.7986117e-11, ..., 3.6233795e-22,\n",
              "        2.6612917e-18, 1.0339914e-26]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_kF6eJsWDJa",
        "outputId": "18058556-40a3-4e3d-8fa4-696909c4d15e"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "model=load_model('handwrittern bangla letter100v2.h5')\n",
        "new_model = tf.keras.models.load_model('handwrittern bangla letter100v2.h5')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 49, 49, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 49, 49, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 49, 49, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 47, 47, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 47, 47, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 47, 47, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 47, 47, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 47, 47, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 47, 47, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 23, 23, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 23, 23, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 23, 23, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 23, 23, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 21, 21, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 21, 21, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 21, 21, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 10, 10, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 10, 10, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 10, 10, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 10, 10, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 10, 10, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 10, 10, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 10, 10, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 10, 10, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 10, 10, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 10, 10, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 10, 10, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 10, 10, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 10, 10, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 10, 10, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 10, 10, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 10, 10, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 10, 10, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 10, 10, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 10, 10, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 10, 10, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 10, 10, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 10, 10, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 10, 10, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 10, 10, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 10, 10, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 10, 10, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 10, 10, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 10, 10, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 10, 10, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 10, 10, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 10, 10, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 10, 10, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 10, 10, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 10, 10, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 10, 10, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 10, 10, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 10, 10, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 10, 10, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 10, 10, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 10, 10, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 10, 10, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 10, 10, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 10, 10, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 10, 10, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 10, 10, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 10, 10, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 10, 10, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 10, 10, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 10, 10, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 10, 10, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 10, 10, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 10, 10, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 10, 10, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 10, 10, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 10, 10, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 10, 10, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 10, 10, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 10, 10, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 10, 10, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 10, 10, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 10, 10, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 10, 10, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 4, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 4, 4, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 4, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 4, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 4, 4, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 4, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 4, 4, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 4, 4, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 4, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 4, 4, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 4, 4, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 4, 4, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 4, 4, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 4, 4, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 4, 4, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 4, 4, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 4, 4, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 4, 4, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 4, 4, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 4, 4, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 4, 4, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 4, 4, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 4, 4, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 4, 4, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 4, 4, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 4, 4, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 4, 4, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 4, 4, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 4, 4, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 4, 4, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 4, 4, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 4, 4, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 4, 4, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 4, 4, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 4, 4, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 4, 4, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 4, 4, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 4, 4, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 4, 4, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 4, 4, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 4, 4, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 4, 4, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 4, 4, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 4, 4, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 4, 4, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 4, 4, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 4, 4, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 4, 4, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 4, 4, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 4, 4, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 4, 4, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 4, 4, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 4, 4, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 4, 4, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 4, 4, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 4, 4, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 4, 4, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 4, 4, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 4, 4, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 4, 4, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 4, 4, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 4, 4, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 4, 4, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 1, 1, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 1, 1, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1, 1, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 1, 1, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 1, 1, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 1, 1, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 1, 1, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 1, 1, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 1, 1, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 1, 1, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 1, 1, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 1, 1, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 1, 1, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 1, 1, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 1, 1, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 1, 1, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 1, 1, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 1, 1, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 1, 1, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 1, 1, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 1, 1, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 1, 1, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 1, 1, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 1, 1, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 1, 1, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 1, 1, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           102450      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,905,234\n",
            "Trainable params: 21,870,802\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKKbAV1IYJP7",
        "outputId": "18a8a15d-204b-4ce6-f96a-fdf4d824d196"
      },
      "source": [
        "loss, acc = new_model.evaluate(test_set, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 - 7s - loss: 0.0822 - accuracy: 0.9770\n",
            "Restored model, accuracy: 97.70%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}